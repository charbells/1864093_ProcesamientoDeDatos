{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPf63xWD6MjikQBV+kBc/z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charbells/1864093_ProcesamientoDeDatos/blob/main/1864093_Tarea3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Universidad Autónoma de Nuevo León\n",
        "# Facultad de Ciencias Físico Matemáticas\n",
        "# Maestría en Ciencia de Datos\n",
        "\n",
        "## Procesamiento y clasificación de datos\n",
        "\n",
        "###### Erick Charbel Lopez Salazar 1864093"
      ],
      "metadata": {
        "id": "8EOFxSMR_crT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introducción\n",
        "\n",
        "El procesamiento de lenguaje natural (NLP) es un campo fundamental en la inteligencia artificial, con aplicaciones que van desde el análisis de sentimientos hasta la clasificación automática de textos. En este estudio, exploramos la clasificación de noticias en diferentes categorías utilizando modelos de aprendizaje automático. Concretamente, empleamos el modelo de Naïve Bayes y una Máquina de Vectores de Soporte (SVM) para analizar noticias de la BBC en cinco categorías: negocios, entretenimiento, política, deportes y tecnología.\n",
        "\n",
        "El objetivo principal es evaluar la efectividad de estos modelos y comparar su desempeño en términos de precisión, exhaustividad y puntuación F1. Para ello, se realizó un preprocesamiento de los datos, incluyendo tokenización, eliminación de stopwords y lematización. Posteriormente, se utilizó la vectorización TF-IDF para transformar el texto en una representación numérica apta para los algoritmos de clasificación.\n",
        "\n",
        "#Datos\n",
        "\n",
        "![Noticias](https://drive.google.com/uc?id=1QQBudAeIuiKA5MUSxorTkb-hXHW7ZyNo)\n",
        "\n",
        "El conjunto de datos utilizado proviene de la BBC y contiene noticias categorizadas en cinco etiquetas (**Business, Enterteinment, Politics, Sport, Tech**). La base consta de 2225 observaciones, donde cada entrada incluye el título, contenido y la categoría correspondiente. El preprocesamiento consistió en la tokenización, eliminación de signos de puntuación, eliminación de stopwords y lematización.\n",
        "\n",
        "![Frecuencias](https://drive.google.com/uc?id=1xWIru3LSHxi611wGfDb6w7nBk6a1WYd1)\n",
        "\n",
        "El gráfico de frecuencias muestra que las diferentes categorias de noticias estan bien balanciadas, es decir, hay una canitidad similar de noticias por cada grupo. Por lo tanto, no hay necesidad de utilizar una estrategia de balanceo de datos.\n",
        "\n",
        "#Experimentación\n",
        "\n",
        "Para la experimentación, se siguieron los siguientes pasos:\n",
        "\n",
        "Preprocesamiento del texto: Conversión del texto a minúsculas, eliminación de signos de puntuación, tokenizacion y lematización con spaCy.\n",
        "\n",
        "Vectorización con TF-IDF: Conversión de los textos preprocesados en vectores numéricos.\n",
        "\n",
        "División de datos: Separación de los datos en conjuntos de entrenamiento (80%) y prueba (20%).\n",
        "\n",
        "Entrenamiento de modelos: Entrenamiento de los modelos de Naïve Bayes y SVM sobre los datos.\n",
        "\n",
        "\n",
        "*   Naïve Bayes: Es un clasificador probabilístico basado en la regla de Bayes, asumiendo independencia condicional entre las características. Es eficiente y funciona bien en tareas de clasificación de texto con datos balanceados.\n",
        "\n",
        "*   Máquinas de Soporte Vectorial (SVM): Este modelo busca encontrar un hiperplano óptimo que separe las clases de manera maximizada. Es especialmente útil en problemas de clasificación de texto debido a su capacidad para manejar datos de alta dimensión.\n",
        "\n",
        "Evaluación: Comparación de los modelos utilizando métricas de precisión, recall y F1-score.\n",
        "\n",
        "#Resultados\n",
        "\n",
        "A continuación, se presentan los resultados obtenidos en la clasificación de noticias utilizando los modelos Naïve Bayes y SVM. Se evalúan en función de métricas estándar para clasificación, incluyendo precisión, recall y F1-score.\n",
        "\n",
        "![Noticias](https://drive.google.com/uc?id=1Mr8Kr1g0Z4G0fxtWVLP2graZeMfza2MI)\n",
        "\n",
        "En base a la tabla, se tienen los siguientes resultados:\n",
        "\n",
        "**Naïve Bayes**\n",
        "\n",
        "    Precisión global: 96%\n",
        "\n",
        "    Mejor desempeño en categoría \"deportes\" (F1-score: 99%)\n",
        "\n",
        "    Peor desempeño en \"entretenimiento\" (F1-score: 93%)\n",
        "\n",
        "**SVM**\n",
        "\n",
        "    Precisión global: 98%\n",
        "\n",
        "    Alto rendimiento en todas las categorías, destacando \"deportes\" con un F1-score del 100%\n",
        "\n",
        "#Conclusiones\n",
        "\n",
        "Los resultados muestran que ambos modelos ofrecen un alto desempeño en la clasificación de noticias, con el modelo SVM obteniendo una ligera ventaja en precisión global (98%) en comparación con Naïve Bayes (96%). En particular, SVM logra una mayor precisión en la categoría de entretenimiento, donde Naïve Bayes tiene un desempeño relativamente menor. Sin embargo, la diferencia entre ambos modelos no es drástica, lo que sugiere que la selección del modelo dependerá del balance entre eficiencia computacional y precisión requerida para la aplicación específica.\n",
        "\n",
        "Este estudio demuestra la efectividad del procesamiento de lenguaje natural en la clasificación de textos y destaca la importancia del preprocesamiento en la mejora del desempeño de los modelos de aprendizaje automático. Además, se observa que el uso de técnicas como la lematización y la eliminación de stopwords tiene un impacto significativo en la calidad de las representaciones textuales, lo que contribuye a la mejora de los resultados finales."
      ],
      "metadata": {
        "id": "hLvQX4v_z-4H"
      }
    }
  ]
}