{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPz5fTOuHWvAGfYHcTWGXu8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charbells/1864093_ProcesamientoDeDatos/blob/main/1864093_Tarea3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Universidad Autónoma de Nuevo León\n",
        "# Facultad de Ciencias Físico Matemáticas\n",
        "# Maestría en Ciencia de Datos\n",
        "\n",
        "## Procesamiento y clasificación de datos\n",
        "\n",
        "###### Erick Charbel Lopez Salazar 1864093"
      ],
      "metadata": {
        "id": "8EOFxSMR_crT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introducción\n",
        "\n",
        "El procesamiento de lenguaje natural (NLP) es un campo fundamental en la inteligencia artificial, con aplicaciones que van desde el análisis de sentimientos hasta la clasificación automática de textos. En este estudio, exploramos la clasificación de noticias en diferentes categorías utilizando modelos de aprendizaje automático. Concretamente, empleamos el modelo de Naïve Bayes y una Máquina de Vectores de Soporte (SVM) para analizar noticias de la BBC en cinco categorías: negocios, entretenimiento, política, deportes y tecnología.\n",
        "\n",
        "El objetivo principal es evaluar la efectividad de estos modelos y comparar su desempeño en términos de precisión, exhaustividad y puntuación F1. Para ello, se realizó un preprocesamiento de los datos, incluyendo tokenización, eliminación de stopwords y lematización. Posteriormente, se utilizó la vectorización TF-IDF para transformar el texto en una representación numérica apta para los algoritmos de clasificación.\n",
        "\n",
        "#Datos\n",
        "\n",
        "El conjunto de datos utilizado proviene de la BBC y contiene noticias categorizadas en cinco etiquetas (**Business, Enterteinment, Politics, Sport, Tech**). La base consta de 2225 observaciones, donde cada entrada incluye el título, contenido y la categoría correspondiente. El preprocesamiento consistió en la tokenización, eliminación de signos de puntuación, eliminación de stopwords y lematización.\n",
        "\n",
        "![Noticias](https://drive.google.com/uc?id=1QQBudAeIuiKA5MUSxorTkb-hXHW7ZyNo)\n",
        "\n",
        "#Experimentación\n",
        "\n",
        "Para la experimentación, se siguieron los siguientes pasos:\n",
        "\n",
        "Preprocesamiento del texto: Conversión del texto a minúsculas, eliminación de signos de puntuación, tokenizacion y lematización con spaCy.\n",
        "\n",
        "Vectorización con TF-IDF: Conversión de los textos preprocesados en vectores numéricos.\n",
        "\n",
        "División de datos: Separación de los datos en conjuntos de entrenamiento (80%) y prueba (20%).\n",
        "\n",
        "Entrenamiento de modelos: Entrenamiento de los modelos de Naïve Bayes y SVM sobre los datos.\n",
        "\n",
        "Evaluación: Comparación de los modelos utilizando métricas de precisión, recall y F1-score.\n",
        "\n",
        "#Resultados\n",
        "\n",
        "A continuación, se presentan los resultados obtenidos en la clasificación de noticias utilizando los modelos Naïve Bayes y SVM. Se evalúan en función de métricas estándar para clasificación, incluyendo precisión, recall y F1-score.\n",
        "\n",
        "![Noticias](https://drive.google.com/uc?id=1Mr8Kr1g0Z4G0fxtWVLP2graZeMfza2MI)\n",
        "\n",
        "En base a la tabla, se tienen los siguientes resultados:\n",
        "\n",
        "**Naïve Bayes**\n",
        "\n",
        "    Precisión global: 96%\n",
        "\n",
        "    Mejor desempeño en categoría \"deportes\" (F1-score: 99%)\n",
        "\n",
        "    Peor desempeño en \"entretenimiento\" (F1-score: 93%)\n",
        "\n",
        "**SVM**\n",
        "\n",
        "    Precisión global: 98%\n",
        "\n",
        "    Alto rendimiento en todas las categorías, destacando \"deportes\" con un F1-score del 100%\n",
        "\n",
        "#Conclusiones\n",
        "\n",
        "Los resultados muestran que ambos modelos ofrecen un alto nivel de precisión. Sin embargo, SVM superó ligeramente a Naïve Bayes en la mayoría de las categorías, alcanzando un rendimiento del 98%. Esto sugiere que, para tareas de clasificación de noticias con características similares, SVM es una mejor opción. No obstante, Naïve Bayes sigue siendo una alternativa válida debido a su eficiencia computacional y simplicidad.\n",
        "\n",
        "Este experimento confirma que el preprocesamiento adecuado del texto y la elección del modelo pueden influir significativamente en la calidad de la clasificación de noticias."
      ],
      "metadata": {
        "id": "hLvQX4v_z-4H"
      }
    }
  ]
}