{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1PjUYgbL4nrROPu5465WOMesuZa84PXv8",
      "authorship_tag": "ABX9TyMe7GdysLIE2qf8OiNQTQpV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charbells/1864093_ProcesamientoDeDatos/blob/main/1864093_Tarea6Reporte.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Universidad Autónoma de Nuevo León\n",
        "# Facultad de Ciencias Físico Matemáticas\n",
        "# Maestría en Ciencia de Datos\n",
        "\n",
        "## Procesamiento y clasificación de datos\n",
        "\n",
        "###### Erick Charbel Lopez Salazar 1864093"
      ],
      "metadata": {
        "id": "V0Pgm3tLn1eP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Clasificación de Sonidos Urbanos con Redes Neuronales Convolucionales y Procesamiento de Señales\n",
        "\n",
        "#Introducción\n",
        "Las Redes Neuronales Convolucionales (CNN por sus siglas en inglés) son un tipo de arquitectura de deep learning especialmente efectiva para procesar datos con estructura espacial o temporal, como imágenes o señales de audio. En este proyecto, utilizamos una CNN 1D (para datos secuenciales) combinada con técnicas de procesamiento de señales para clasificar sonidos urbanos.\n",
        "\n",
        "¿Por qué usar CNNs para audio?\n",
        "\n",
        "Extracción automática de características: A diferencia de métodos tradicionales que requieren ingeniería manual de features (como MFCCs estáticos), las CNN aprenden patrones jerárquicos directamente de los datos.\n",
        "\n",
        "Captura de dependencias temporales: Las capas convolucionales detectan patrones locales en ventanas de tiempo (ej: un ladrido de perro tiene firmas espectrales distintivas en ciertas frecuencias).\n",
        "\n",
        "Robustez a variaciones: Invariantes a pequeñas deformaciones en la señal (útil para sonidos con ruido ambiental).\n",
        "\n",
        "El objetivo de este proyecto fue desarrollar un modelo de aprendizaje automático capaz de clasificar sonidos urbanos del dataset UrbanSound8K, que contiene 10 clases como \"air_conditioner\", \"car_horn\", \"gun_shot\", entre otros.\n",
        "\n",
        "Se implementó una CNN con transformada wavelet y MFCCs, combinando técnicas de procesamiento de señales y deep learning para lograr una clasificación robusta.\n",
        "\n",
        "#Datos\n",
        "Dataset utilizado:\n",
        "\n",
        "*   UrbanSound8K de hugging face (8,732 audios, 10 clases diferentes).\n",
        "*   Distribución desigual de muestras (ej: \"car_horn\" tiene 86 muestras vs. \"street_music\" con 200).\n",
        "\n",
        "Normalización y Padding:\n",
        "\n",
        "*   Escalado de amplitud: Normalización a [-1, 1].\n",
        "\n",
        "*   Ajuste de duración: Todos los audios se truncaron o rellenaron (padding) a 4 segundos (para uniformidad).\n",
        "\n",
        "Balanceo de Clases con SMOTE:\n",
        "\n",
        "*   Problema: Clases minoritarias (gun_shot, car_horn) afectan el aprendizaje.\n",
        "\n",
        "*   Solución: Se aplicó SMOTE (Synthetic Minority Over-sampling Technique) para generar muestras sintéticas y equilibrar el dataset.\n",
        "\n",
        "A continuación se muestra la imagen de ejemplo de un sonido:\n",
        "![imagen 1](https://drive.google.com/uc?id=1s_jkjZgELIoFBRb130qjClEclEULd4gy)\n",
        "\n",
        "#Metodología\n",
        "Extracción de características\n",
        "Wavelet (Db4):\n",
        "\n",
        "*   Descomposición en 5 niveles.\n",
        "\n",
        "*   Estadísticas por nivel (media, desviación, percentiles).\n",
        "\n",
        "MFCCs + Deltas:\n",
        "\n",
        "*   13 coeficientes + derivadas temporales.\n",
        "\n",
        "Otras características espectrales:\n",
        "\n",
        "*   Centroid, bandwidth, zero-crossing rate.\n",
        "\n",
        "Modelo CNN:\n",
        "\n",
        "*   3 capas Conv1D (128, 256, 512 filtros) + BatchNorm + Dropout.\n",
        "\n",
        "| Capa                  | Hiperparámetros                     | Justificación Técnica                  |\n",
        "|-----------------------|------------------------------------|----------------------------------------|\n",
        "| **InputLayer**        | `(None, 4000, 1)`                 | 4 seg @ 1kHz (óptimo para sonidos urbanos) |\n",
        "| **Conv1D + BatchNorm**| 128 filtros, kernel=5, strides=2   | Gran kernel para patrones de larga duración |\n",
        "| **Conv1D + BatchNorm**| 256 filtros, kernel=3, dilation=2  | Captura dependencias multi-escala       |\n",
        "| **DepthwiseConv1D**   | 512 filtros, kernel=3              | Extracción eficiente de features        |\n",
        "| **GlobalAvgPooling1D**| -                                  | Reduce parámetros vs Flatten            |\n",
        "\n",
        "*   GlobalAveragePooling para reducir overfitting.\n",
        "\n",
        "Entrenamiento:\n",
        "\n",
        "*   Optimizador: Adam (LR=0.0001).\n",
        "\n",
        "*   Early Stopping (paciencia=10 épocas).\n",
        "\n",
        "SMOTE para balancear clases desequilibradas.\n",
        "\n",
        "# Resultados\n",
        "\n",
        "La siguiente tabla presenta el desempeño del modelo en cada una de las 10 clases de sonidos urbanos, evaluado mediante Precisión (Precision), Recall (Sensibilidad) y F1-Score, junto con el número de muestras de prueba para cada categoría:\n",
        "\n",
        "| Clase               | Precisión | Recall | F1-Score | Muestras |\n",
        "|---------------------|----------:|-------:|---------:|---------:|\n",
        "| air_conditioner     |      0.91 |   0.91 |     0.91 |      200 |\n",
        "| car_horn            |      0.81 |   0.85 |     0.83 |       86 |\n",
        "| children_playing    |      0.85 |   0.78 |     0.81 |      200 |\n",
        "| dog_bark            |      0.94 |   0.83 |     0.88 |      200 |\n",
        "| drilling            |      0.90 |   0.86 |     0.88 |      200 |\n",
        "| engine_idling       |      0.93 |   0.91 |     0.92 |      200 |\n",
        "| gun_shot            |      0.86 |   0.97 |     0.91 |       75 |\n",
        "| jackhammer          |      0.84 |   0.90 |     0.87 |      200 |\n",
        "| siren               |      0.91 |   0.92 |     0.92 |      186 |\n",
        "| street_music        |      0.77 |   0.84 |     0.80 |      200 |\n",
        "\n",
        "*   Precisión (Precision): Indica cuántos de los ejemplos clasificados como positivos realmente son positivos. Ejemplo: Para gun_shot, un 86% de precisión significa que, de todos los audios que el modelo predijo como \"disparo\", el 86% eran correctos.\n",
        "\n",
        "*   Recall (Sensibilidad): Mide la capacidad del modelo para detectar todos los casos positivos. Ejemplo: gun_shot tiene un 97% de recall, lo que indica que el modelo identifica casi todos los disparos reales, pero con algunos falsos positivos.\n",
        "\n",
        "*   F1-Score: Combinación de precisión y recall (ideal para clases desbalanceadas). Ejemplo: car_horn (F1=0.83) tiene un desempeño bueno a pesar de tener solo 86 muestras, gracias al uso de SMOTE.\n",
        "\n",
        "### Métricas globales\n",
        "\n",
        "Accuracy: El modelo clasifica correctamente el 87% de los audios en total.\n",
        "\n",
        "Weighted avg F1: Media del F1-Score de todas las clases ponderado es de 0.87.\n",
        "\n",
        "### Gráfica de entrenamiento\n",
        "\n",
        "![imagen 2](https://drive.google.com/uc?id=1cpcct2YAvN2T_Qd_NbnuAWaqpo972Gyt)\n",
        "\n",
        "La gráfica muestra la evolución de las métricas de pérdida (loss) y exactitud (accuracy) durante el entrenamiento y validación del modelo a lo largo de las 100 épocas.\n",
        "\n",
        "El modelo converge establemente después de ~60 épocas.\n",
        "\n",
        "Sin overfitting (brecha mínima entre train/val).\n",
        "\n",
        "# Conclusiones\n",
        "\n",
        "Este proyecto ha demostrado de manera contundente que la sinergia entre técnicas avanzadas de procesamiento de señales (transformada Wavelet + MFCCs) y arquitecturas de Deep Learning (CNN 1D) ofrece un enfoque poderoso para la clasificación robusta de sonidos urbanos, superando significativamente los métodos tradicionales basados únicamente en características acústicas convencionales.\n",
        "\n",
        "###Contribuciones Clave\n",
        "Alto Desempeño en Clasificación:\n",
        "\n",
        "*   Se logró un accuracy del 87% en un dataset desbalanceado (UrbanSound8K), con un F1-score promedio de 0.87, demostrando que el modelo generaliza efectivamente incluso en entornos acústicos complejos.\n",
        "\n",
        "*   Clases críticas como gun_shot (recall: 97%) y siren (F1: 0.92) fueron identificadas con alta confiabilidad, lo que es crucial para aplicaciones de seguridad pública.\n",
        "\n",
        "Solución a Desafíos Comunes:\n",
        "\n",
        "*   El uso de SMOTE permitió mejorar el F1-score en clases minoritarias (ej: car_horn).\n",
        "\n",
        "*   La transformada Wavelet complementó a los MFCCs para capturar tanto detalles espectrales como temporales, mejorando la discriminación de sonidos con firmas acústicas similares (ej: drilling vs jackhammer).\n",
        "\n",
        "Modelo Robustez y Eficiencia:\n",
        "\n",
        "*   La arquitectura CNN 1D, combinada con Batch Normalization y Dropout, mostró un entrenamiento estable sin overfitting, como lo confirman las curvas de aprendizaje.\n",
        "\n",
        "*   A pesar de la complejidad añadida por la extracción de características wavelet, el modelo mantuvo un tiempo de inferencia aceptable (~2 segundos en CPU), con margen para optimización.\n",
        "\n",
        "###Limitaciones y Lecciones Aprendidas\n",
        "*   Street Music (F1: 0.80) sigue siendo un reto debido a su diversidad acústica, sugiriendo la necesidad de técnicas de aumento de datos más sofisticadas (ej: mezcla de espectrogramas).\n",
        "\n",
        "*   La dependencia de múltiples etapas de preprocesamiento (wavelet + MFCCs) incrementa la latencia, lo que podría ser crítico para aplicaciones en tiempo real."
      ],
      "metadata": {
        "id": "elu6GzPmYCes"
      }
    }
  ]
}